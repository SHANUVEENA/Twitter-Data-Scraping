{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOT5szGb2VqeNRisc96Qfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHANUVEENA/Twitter-Data-Scraping/blob/main/Streamlit_app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from pandas.api.types import (\n",
        "    is_categorical_dtype,\n",
        "    is_datetime64_any_dtype,\n",
        "    is_numeric_dtype,\n",
        "    is_object_dtype,\n",
        ")\n",
        "\n",
        "st.title(\"Auto Filter Dataframes in Streamlit\")\n",
        "\n",
        "st.write(\n",
        "    \"\"\"This app accomodates the blog [here](https://blog.streamlit.io/auto-generate-a-dataframe-filtering-ui-in-streamlit-with-filter_dataframe/)\n",
        "    and walks you through one example of how the Streamlit\n",
        "    Data Science Team builds add-on functions to Streamlit.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "def filter_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a UI on top of a dataframe to let viewers filter columns\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Original dataframe\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered dataframe\n",
        "    \"\"\"\n",
        "    modify = st.checkbox(\"Add filters\")\n",
        "\n",
        "    if not modify:\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Try to convert datetimes into a standard format (datetime, no timezone)\n",
        "    for col in df.columns:\n",
        "        if is_object_dtype(df[col]):\n",
        "            try:\n",
        "                df[col] = pd.to_datetime(df[col])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if is_datetime64_any_dtype(df[col]):\n",
        "            df[col] = df[col].dt.tz_localize(None)\n",
        "\n",
        "    modification_container = st.container()\n",
        "\n",
        "    with modification_container:\n",
        "        to_filter_columns = st.multiselect(\"Filter dataframe on\", df.columns)\n",
        "        for column in to_filter_columns:\n",
        "            left, right = st.columns((1, 20))\n",
        "            left.write(\"â†³\")\n",
        "            # Treat columns with < 10 unique values as categorical\n",
        "            if is_categorical_dtype(df[column]) or df[column].nunique() < 10:\n",
        "                user_cat_input = right.multiselect(\n",
        "                    f\"Values for {column}\",\n",
        "                    df[column].unique(),\n",
        "                    default=list(df[column].unique()),\n",
        "                )\n",
        "                df = df[df[column].isin(user_cat_input)]\n",
        "            elif is_numeric_dtype(df[column]):\n",
        "                _min = float(df[column].min())\n",
        "                _max = float(df[column].max())\n",
        "                step = (_max - _min) / 100\n",
        "                user_num_input = right.slider(\n",
        "                    f\"Values for {column}\",\n",
        "                    _min,\n",
        "                    _max,\n",
        "                    (_min, _max),\n",
        "                    step=step,\n",
        "                )\n",
        "                df = df[df[column].between(*user_num_input)]\n",
        "            elif is_datetime64_any_dtype(df[column]):\n",
        "                user_date_input = right.date_input(\n",
        "                    f\"Values for {column}\",\n",
        "                    value=(\n",
        "                        df[column].min(),\n",
        "                        df[column].max(),\n",
        "                    ),\n",
        "                )\n",
        "                if len(user_date_input) == 2:\n",
        "                    user_date_input = tuple(map(pd.to_datetime, user_date_input))\n",
        "                    start_date, end_date = user_date_input\n",
        "                    df = df.loc[df[column].between(start_date, end_date)]\n",
        "            else:\n",
        "                user_text_input = right.text_input(\n",
        "                    f\"Substring or regex in {column}\",\n",
        "                )\n",
        "                if user_text_input:\n",
        "                    df = df[df[column].str.contains(user_text_input)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins.csv\"\n",
        ")\n",
        "st.dataframe(filter_dataframe(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u--opsIaAy8m",
        "outputId": "3c5d12b5-f30e-41c4-be4c-b59e0807cc6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}